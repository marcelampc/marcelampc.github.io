<!DOCTYPE html>
<html lang="en">

  <head>

    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="Researcher in Deep Learning for Computer Vision" content="">
    <meta name="Marcela" content="">

    <title>MC Internship</title>

    <!-- Bootstrap core CSS -->
    <link href="../vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom fonts for this template -->
    <link href="https://fonts.googleapis.com/css?family=Saira+Extra+Condensed:100,200,300,400,500,600,700,800,900" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Open+Sans:300,300i,400,400i,600,600i,700,700i,800,800i" rel="stylesheet">
    <link href="../vendor/font-awesome/css/font-awesome.min.css" rel="stylesheet">
    <link href="../vendor/devicons/css/devicons.min.css" rel="stylesheet">
    <link href="../vendor/simple-line-icons/css/simple-line-icons.css" rel="stylesheet">

    <!-- Custom styles for this template -->
    <link href='../css/resume.css' rel="stylesheet">

    <link rel="shortcut icon" type="../image/png" href="../icon_.png"/>

  </head>

  <body id="page-top">

    <nav class="navbar navbar-expand-lg navbar-dark bg-primary fixed-top" id="sideNav">
      <a class="navbar-brand js-scroll-trigger" href="#page-top">
        <span class="d-block d-lg-none">Marcela Carvalho</span>
        <span class="d-none d-lg-block">
          <img class="img-fluid img-profile rounded-circle mx-auto mb-2" src="../img/me.png" alt="">
          <h3> Marcela Carvalho</h3>
        </span>
      </a>
      <hr class="divider-long">
      <h6 id="profile-resume"> I'm a PhD student at <a href=https://www.onera.fr/ class="class2"> ONERA </a> working on Deep Learning for Optics and Computer vision. </h6>
      <hr class="divider-short">
      <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
      </button>
      <div class="collapse navbar-collapse" id="navbarSupportedContent">
        <ul class="navbar-nav">
          <li class="nav-item">
            <a class="nav-link js-scroll-trigger" href="../index.html">Home</a>
          </li>
          <li class="nav-item">
            <a class="nav-link js-scroll-trigger" href="#internship">Internship</a>
          </li>
        </ul>
      </div>
    </nav>

    <div class="container-fluid p-0">


      <section class="resume-section p-3 p-lg-5 d-flex d-column" id="internship">
        <div class="my-auto">
          <h1 class="mb-0">Research
            <span class="text-primary">Internship</span>
            DTIS/ONERA
          </h1>
          <h2>Title: <span class="text-primary">Deep neural networks for 3D point cloud prediction from a single image</span></h2>
          <!-- <img src="img/internship_pointcloud.png" class="responsive" alt="RGB_to_PointCloud_Kitti"> -->


        <p>3D estimation is crucial for scene understanding (e.g., autonomous driving) and accurate 3D reconstruction (e.g., 3D mapping, robotics). 3D from a single image has recently reached great performances thanks to deep neural networks. This might be a data acquisition paradigm shift, away from stereo vision and active laser scanners.</p>

        <p>We, at ONERA/DTIS, developed D3-Net [Carvalho et al., 2018a-b], one of the top state-of-the-art approaches for depth estimation using a deep learning approach, awarded by a Best Paper Award at RFIAP2018, the French machine learning conference.</p>

        <p>To go further on our research, the objective of the internship is to push this work to develop convolutional neural networks (CNNs) to directly estimate 3D point clouds, instead of depth rasters. Indeed, 3D point clouds are the standard in 3D data acquisition with laser and photogrammetry, and hence in 3D perception.</p>

        <p>Especially, the intern will tackle two problems:</p>

        <p><o1>
            <li class="itemize">build convolutional network models for prediction of 3D real points. A particular care will be given to the design of the loss function, as the same geometry may admit different point cloud representations. Solutions based on Optimal Transport will be investigated [Fan et al., 2017]; and</li>
            <li class="itemize">predict only accurate points to avoid further errors in reconstruction algorithms. Various approches will be compared, including simultaneous uncertainty prediction as in [Carvalho et al., 2018a], [Kendall & Gal, 2017], understanding of image hints which allow to estimate 3D: defocus, edges, scene statistics.</li>
        </o1></p>

        <p><o1><c2>Responsibilities</c2>
        <li class="itemize">Design and development of CNNs for 3D point cloud prediction from a single image;</li>
        <li class="itemize">Software development (Python) of CNNs using open libraries such as PyTorch or TensorFlow;
        <li class="itemize">Application to robotics and computer graphics benchmarks and datasets such as ShapeNet, Stanford 2D-3D-S, or Semantic3D.</li>
      </o1></p>

      <p><o1><c2>Basic Qualifications</c2>
        <li class="itemize"> Current enrollment in Master 2, 3rd year of Engineering School, or equivalent.</li>
        <li class="itemize"> Good spoken and written English.</li>
        <li class="itemize"> Experience in software development and debugging.</li>
        <li class="itemize"> Ability to work autonomously (we'll still be there, don't worry).</li>
        
      </o1></p>
      
      <p><o1><c2>Preferred Qualification</c2>            
        <li class="itemize"> Previous experience in Python.</li>
        <li class="itemize"> Knowledge in Image Processing/Computer Vision.</li>
          <li class="itemize"> Experience with PyTorch and/or TensorFlow, Git and LaTeX.</li>
          <li class="itemize"> Academic research experience.</li>
          <li class="itemize"> Research and software engineer experience demonstrated via an internship, work experience, or robotics/coding competitions.</li>
        </o1></p>

       <p><b> This internship will be held for 4-6 months in any period between January and September 2019.<b></p>
         
       <p> This project may continue as a PhD thesis with our team. </b> </b></p>
         
            
      <p><c3>Interest to join our team? Please send us an email with your CV and motivation letter to  <c4><a href="mailto:marcela.carvalho@onera.fr">marcela.carvalho@onera.fr</a></c4> (Marcela Carvalho), <c4><a href="mailto:bertrand.le_saux@onera.fr">bertrand.le_saux@onera.fr</a></c4> (Bertrand Le Saux) and <c4><a href="mailto:pauline.trouve@onera.fr">pauline.trouve@onera.fr</a></c4> (Pauline Trouvé-Peloux) </c3>.</p>

      <p>You may find the original internship offer <a href=https://w3.onera.fr/stages/sites/w3.onera.fr.stages/files/dtis-2019-65.pdf>here</a> and other internships with our team may be found <a href=https://w3.onera.fr/stages/stages-dtis>here</a>. </p>

      

      <p><o1><c2>References</c2>  
        <li class="itemize"> [Carvalho et al., 2018b] <a href=../material/docs/2018/regression_losses_icip_2018.pdf class="class1"> On Regression Losses for Deep Depth Estimation</a>, M. Carvalho, B. Le Saux, P. Trouvé-Peloux, F. Champagnat, A. Almansa IEEE Int. Conf. on Image Processing (ICIP’2018) Athens, Greece, October 2018.</li>
        <li class="itemize"> [Carvalho et al., 2018a] <a href=https://arxiv.org/abs/1809.01567 class="class1"> Deep Depth from Defocus: how can defocus blur improve 3D estimation using dense neural networks?</a>, M. Carvalho, B. Le Saux, P. Trouvé-Peloux, F. Champagnat, A. Almansa ECCV / Workshop on 3D Reconstruction in the Wild, Munich, Germany, September 2018.</li>
        <li class="itemize"> [Fan et al., 2017] A Point Set Generation Network for 3D Object Reconstruction from a Single Image, Haoqiang Fan, Hao Su, Leonidas J. Guibas CVPR 2017, Hawaii, USA, July 2017.</li>
        <li class="itemize"> [Kendall & Gal, 2017] What uncertainties do we need in Bayesian deep learning for computer vision?, A. Kendall, Y. Gal, NIPS 2017, Long Beach, Cal., USA, December 2017.</li>
      </o1></p>


      </section>

        </div>
      </section> 

    <!-- Bootstrap core JavaScript -->
    <script src="vendor/jquery/jquery.min.js"></script>
    <script src="vendor/bootstrap/js/bootstrap.bundle.min.js"></script>

    <!-- Plugin JavaScript -->
    <script src="vendor/jquery-easing/jquery.easing.min.js"></script>

    <!-- Custom scripts for this template -->
    <script src="js/resume.min.js"></script>

  </body>

</html>
